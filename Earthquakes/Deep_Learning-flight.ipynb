{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flightdate</th>\n",
       "      <th>airline</th>\n",
       "      <th>carrier</th>\n",
       "      <th>origin</th>\n",
       "      <th>orignum</th>\n",
       "      <th>destination</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>deptime</th>\n",
       "      <th>depdetla</th>\n",
       "      <th>depdelay</th>\n",
       "      <th>...</th>\n",
       "      <th>arrdelta</th>\n",
       "      <th>arrdelayu</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>cancelreason</th>\n",
       "      <th>distance</th>\n",
       "      <th>carrierdelay</th>\n",
       "      <th>weatherdelay</th>\n",
       "      <th>NASdelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>lateaircraftdelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/17/14</td>\n",
       "      <td>20409</td>\n",
       "      <td>B6</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>1</td>\n",
       "      <td>JFK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/6/14</td>\n",
       "      <td>19977</td>\n",
       "      <td>UA</td>\n",
       "      <td>AGS</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/2/14</td>\n",
       "      <td>19977</td>\n",
       "      <td>UA</td>\n",
       "      <td>ANC</td>\n",
       "      <td>3</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/1/14</td>\n",
       "      <td>19977</td>\n",
       "      <td>UA</td>\n",
       "      <td>ANC</td>\n",
       "      <td>3</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/10/14</td>\n",
       "      <td>19977</td>\n",
       "      <td>UA</td>\n",
       "      <td>ANC</td>\n",
       "      <td>3</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  flightdate  airline carrier origin  orignum destination  Unnamed: 6  \\\n",
       "0    4/17/14    20409      B6    ABQ        1         JFK         NaN   \n",
       "1     4/6/14    19977      UA    AGS        2         ATL         NaN   \n",
       "2     4/2/14    19977      UA    ANC        3         DEN         NaN   \n",
       "3     4/1/14    19977      UA    ANC        3         DEN         NaN   \n",
       "4    4/10/14    19977      UA    ANC        3         DEN         NaN   \n",
       "\n",
       "   deptime  depdetla  depdelay        ...          arrdelta  arrdelayu  \\\n",
       "0        4         5         5        ...               2.0        2.0   \n",
       "1        1        86        86        ...              81.0       81.0   \n",
       "2        3         4         4        ...              21.0       21.0   \n",
       "3        4         5         5        ...              -3.0        0.0   \n",
       "4        4         5         5        ...             -23.0        0.0   \n",
       "\n",
       "   cancelled  cancelreason distance  carrierdelay  weatherdelay  NASdelay  \\\n",
       "0          0           NaN     1826           NaN           NaN       NaN   \n",
       "1          0           NaN      143           0.0          54.0       0.0   \n",
       "2          0           NaN     2405           0.0           0.0      21.0   \n",
       "3          0           NaN     2405           NaN           NaN       NaN   \n",
       "4          0           NaN     2405           NaN           NaN       NaN   \n",
       "\n",
       "   SecurityDelay  lateaircraftdelay  \n",
       "0            NaN                NaN  \n",
       "1            0.0               27.0  \n",
       "2            0.0                0.0  \n",
       "3            NaN                NaN  \n",
       "4            NaN                NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calhouse = pd.read_csv('flights200.csv')\n",
    "calhouse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = calhouse[[\"orignum\", \"deptime\"]]\n",
    "y = calhouse[\"cancelled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a27d3d400>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Data\n",
    "X1=X.values\n",
    "#y=y.values\n",
    "\n",
    "plt.scatter(X1[:, 0], X1[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-25fb99ba413a3271",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e1de5d9b7942f68",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9532e12246e485d5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/envs/PythonData/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Transform the training and testing data using the X_scaler\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "y_train_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec399a95e133cb58",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# first, create a normal neural network with 2 inputs, 6 hidden nodes, and 2 outputs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=6, activation='relu', input_dim=2))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 6)                 18        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.70546635,  0.18701609],\n",
       "       [-0.30886399,  0.18701609],\n",
       "       [ 1.4033168 , -0.70353672],\n",
       "       [-0.81244657, -1.14881312],\n",
       "       [-1.11459612,  1.0775689 ],\n",
       "       [ 1.4033168 ,  0.63229249],\n",
       "       [ 1.10116725, -0.25826031],\n",
       "       [ 1.30260029, -0.70353672],\n",
       "       [ 2.0076159 ,  0.18701609],\n",
       "       [ 1.4033168 ,  1.5228453 ],\n",
       "       [-0.30886399, -0.70353672],\n",
       "       [-0.20814747,  1.0775689 ],\n",
       "       [ 0.69830118, -1.14881312],\n",
       "       [-0.91316309, -1.14881312],\n",
       "       [-1.51746219, -0.70353672],\n",
       "       [-1.71889522,  1.5228453 ],\n",
       "       [ 1.4033168 ,  1.5228453 ],\n",
       "       [-0.10743095, -0.70353672],\n",
       "       [-0.81244657, -1.14881312],\n",
       "       [-0.4095805 , -1.14881312],\n",
       "       [-0.10743095,  0.18701609],\n",
       "       [-0.71173005, -0.70353672],\n",
       "       [ 1.4033168 ,  0.18701609],\n",
       "       [-0.10743095,  0.18701609],\n",
       "       [-0.10743095,  1.96812171],\n",
       "       [ 1.30260029, -0.70353672],\n",
       "       [-0.10743095,  1.5228453 ],\n",
       "       [-1.61817871,  0.63229249],\n",
       "       [-0.10743095, -1.14881312],\n",
       "       [-0.10743095, -0.70353672],\n",
       "       [-0.00671443,  0.63229249],\n",
       "       [ 1.00045073, -0.25826031],\n",
       "       [-0.00671443, -1.14881312],\n",
       "       [-0.30886399, -1.14881312],\n",
       "       [-0.10743095,  1.96812171],\n",
       "       [ 0.1947186 ,  0.63229249],\n",
       "       [-1.61817871,  1.5228453 ],\n",
       "       [-0.30886399, -1.14881312],\n",
       "       [ 1.70546635,  1.5228453 ],\n",
       "       [ 1.4033168 ,  0.18701609],\n",
       "       [-0.81244657,  0.18701609],\n",
       "       [ 1.4033168 ,  1.5228453 ],\n",
       "       [-1.11459612, -1.14881312],\n",
       "       [ 1.10116725,  1.96812171],\n",
       "       [ 1.4033168 ,  1.96812171],\n",
       "       [ 0.89973422, -0.70353672],\n",
       "       [-0.10743095,  0.18701609],\n",
       "       [-0.10743095, -0.25826031],\n",
       "       [ 1.80618287, -0.70353672],\n",
       "       [ 0.69830118, -0.25826031],\n",
       "       [ 1.4033168 , -0.70353672],\n",
       "       [-0.30886399,  1.0775689 ],\n",
       "       [-1.41674567, -0.70353672],\n",
       "       [-0.20814747,  1.0775689 ],\n",
       "       [ 0.7990177 , -1.14881312],\n",
       "       [-1.71889522,  0.18701609],\n",
       "       [-0.30886399, -0.25826031],\n",
       "       [-0.20814747, -0.25826031],\n",
       "       [ 0.69830118, -1.14881312],\n",
       "       [-1.71889522,  1.5228453 ],\n",
       "       [-0.10743095,  1.5228453 ],\n",
       "       [-1.92032826,  0.63229249],\n",
       "       [ 1.4033168 ,  0.63229249],\n",
       "       [-0.30886399,  1.5228453 ],\n",
       "       [-0.10743095,  1.5228453 ],\n",
       "       [-0.4095805 , -1.14881312],\n",
       "       [-0.71173005,  1.96812171],\n",
       "       [ 1.70546635,  0.18701609],\n",
       "       [-0.20814747,  0.63229249],\n",
       "       [ 1.10116725, -0.25826031],\n",
       "       [-0.81244657, -1.14881312],\n",
       "       [-0.51029702, -1.14881312],\n",
       "       [-0.30886399,  0.63229249],\n",
       "       [-0.20814747,  1.5228453 ],\n",
       "       [ 0.69830118, -1.14881312],\n",
       "       [ 1.10116725,  0.63229249],\n",
       "       [ 1.70546635, -0.25826031],\n",
       "       [-0.20814747,  0.63229249],\n",
       "       [ 0.29543512, -0.70353672],\n",
       "       [-1.61817871,  0.18701609],\n",
       "       [-1.11459612,  0.63229249],\n",
       "       [-0.20814747, -0.25826031],\n",
       "       [ 1.4033168 ,  0.63229249],\n",
       "       [-0.10743095, -0.70353672],\n",
       "       [-0.00671443, -1.14881312],\n",
       "       [-1.41674567, -0.25826031],\n",
       "       [-0.00671443, -1.14881312],\n",
       "       [-1.61817871,  0.18701609],\n",
       "       [ 1.30260029,  1.96812171],\n",
       "       [-0.10743095,  0.18701609],\n",
       "       [ 0.69830118, -1.14881312],\n",
       "       [ 0.1947186 , -1.14881312],\n",
       "       [-0.10743095,  0.63229249],\n",
       "       [ 1.50403332,  0.18701609],\n",
       "       [-0.4095805 , -1.14881312],\n",
       "       [-1.61817871,  1.5228453 ],\n",
       "       [-0.91316309, -1.14881312],\n",
       "       [ 1.20188377, -0.70353672],\n",
       "       [-0.10743095,  0.18701609],\n",
       "       [-0.30886399, -1.14881312],\n",
       "       [-0.81244657, -1.14881312],\n",
       "       [-1.31602915, -0.25826031],\n",
       "       [-0.30886399,  1.0775689 ],\n",
       "       [-0.81244657, -0.70353672],\n",
       "       [-1.41674567,  0.18701609],\n",
       "       [-1.71889522,  0.63229249],\n",
       "       [ 1.30260029,  1.0775689 ],\n",
       "       [-0.81244657, -1.14881312],\n",
       "       [ 0.69830118, -1.14881312],\n",
       "       [ 0.1947186 ,  1.0775689 ],\n",
       "       [ 1.70546635, -0.70353672],\n",
       "       [-1.11459612,  0.18701609],\n",
       "       [-0.10743095, -1.14881312],\n",
       "       [-0.10743095,  1.5228453 ],\n",
       "       [ 1.4033168 ,  0.18701609],\n",
       "       [-1.61817871, -0.25826031],\n",
       "       [-0.51029702, -0.70353672],\n",
       "       [-0.00671443, -1.14881312],\n",
       "       [-1.81961174, -0.70353672],\n",
       "       [-0.61101354,  1.96812171],\n",
       "       [-1.41674567, -0.70353672],\n",
       "       [-0.51029702,  1.96812171],\n",
       "       [-0.4095805 ,  1.5228453 ],\n",
       "       [-1.61817871, -0.70353672],\n",
       "       [ 1.70546635, -1.14881312],\n",
       "       [ 0.59758467, -1.14881312],\n",
       "       [-0.20814747,  0.18701609],\n",
       "       [-0.10743095, -0.70353672],\n",
       "       [-0.30886399, -0.70353672],\n",
       "       [-0.81244657, -1.14881312],\n",
       "       [ 0.69830118, -0.70353672],\n",
       "       [ 1.10116725, -0.25826031],\n",
       "       [ 1.00045073, -1.14881312],\n",
       "       [ 0.39615163, -1.14881312],\n",
       "       [ 0.69830118, -1.14881312],\n",
       "       [-0.10743095, -0.25826031],\n",
       "       [-1.51746219,  1.0775689 ],\n",
       "       [ 1.4033168 ,  0.18701609],\n",
       "       [-1.41674567,  1.96812171],\n",
       "       [ 0.1947186 ,  1.0775689 ],\n",
       "       [-0.30886399,  0.18701609],\n",
       "       [ 0.09400208, -0.25826031],\n",
       "       [ 0.69830118, -1.14881312],\n",
       "       [ 1.70546635, -0.70353672],\n",
       "       [-0.30886399, -1.14881312],\n",
       "       [ 0.1947186 ,  1.0775689 ],\n",
       "       [ 0.29543512, -1.14881312],\n",
       "       [-0.30886399,  0.18701609],\n",
       "       [ 0.49686815, -0.25826031],\n",
       "       [-1.0138796 , -0.25826031]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape#_categorical.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195    0\n",
       "73     0\n",
       "173    0\n",
       "53     1\n",
       "33     0\n",
       "180    0\n",
       "158    0\n",
       "168    0\n",
       "200    0\n",
       "184    0\n",
       "69     0\n",
       "90     0\n",
       "150    1\n",
       "42     1\n",
       "17     0\n",
       "5      0\n",
       "185    0\n",
       "99     0\n",
       "48     1\n",
       "66     1\n",
       "107    0\n",
       "54     0\n",
       "177    0\n",
       "106    0\n",
       "119    0\n",
       "167    0\n",
       "116    0\n",
       "12     0\n",
       "120    1\n",
       "95     0\n",
       "      ..\n",
       "22     0\n",
       "61     0\n",
       "63     0\n",
       "7      0\n",
       "197    1\n",
       "141    1\n",
       "86     0\n",
       "96     0\n",
       "68     0\n",
       "50     1\n",
       "142    0\n",
       "157    0\n",
       "156    1\n",
       "139    1\n",
       "146    1\n",
       "101    0\n",
       "20     0\n",
       "178    0\n",
       "25     0\n",
       "134    0\n",
       "71     0\n",
       "129    0\n",
       "144    1\n",
       "192    0\n",
       "79     1\n",
       "133    0\n",
       "137    1\n",
       "72     0\n",
       "140    0\n",
       "37     0\n",
       "Name: cancelled, Length: 150, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train#_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5cf2fbdbea0ed50b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 0s - loss: 0.5990 - acc: 0.7200\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.5888 - acc: 0.7200\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.5784 - acc: 0.7200\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.5686 - acc: 0.7333\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.5591 - acc: 0.7467\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.5496 - acc: 0.7800\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.5419 - acc: 0.7800\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.5333 - acc: 0.7867\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.5256 - acc: 0.7933\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.5186 - acc: 0.8000\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.5116 - acc: 0.8133\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.5047 - acc: 0.8400\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4984 - acc: 0.8467\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4924 - acc: 0.8467\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.4863 - acc: 0.8600\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4805 - acc: 0.8800\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.4751 - acc: 0.8800\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.4699 - acc: 0.8867\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.4646 - acc: 0.8867\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.4597 - acc: 0.8867\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4549 - acc: 0.8867\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4498 - acc: 0.8867\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4452 - acc: 0.8867\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4407 - acc: 0.8867\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4362 - acc: 0.8867\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.4319 - acc: 0.8867\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4276 - acc: 0.8933\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4233 - acc: 0.8933\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4193 - acc: 0.8933\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.4152 - acc: 0.8933\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.4113 - acc: 0.8933\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.4073 - acc: 0.8933\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.4034 - acc: 0.8933\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.3998 - acc: 0.9000\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.3960 - acc: 0.9067\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.3923 - acc: 0.9067\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.3886 - acc: 0.9067\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.3850 - acc: 0.9067\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.3814 - acc: 0.9067\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.3778 - acc: 0.9133\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.3743 - acc: 0.9067\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.3709 - acc: 0.9067\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.3675 - acc: 0.9067\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.3641 - acc: 0.9133\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.3608 - acc: 0.9200\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.3575 - acc: 0.9267\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.3543 - acc: 0.9267\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.3511 - acc: 0.9267\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.3481 - acc: 0.9267\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.3449 - acc: 0.9267\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.3419 - acc: 0.9267\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.3389 - acc: 0.9267\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.3359 - acc: 0.9267\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.3329 - acc: 0.9267\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.3299 - acc: 0.9267\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.3270 - acc: 0.9267\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.3242 - acc: 0.9267\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.3214 - acc: 0.9267\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.3186 - acc: 0.9267\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.3158 - acc: 0.9267\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.3131 - acc: 0.9267\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.3103 - acc: 0.9267\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.3077 - acc: 0.9267\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.3050 - acc: 0.9267\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.3025 - acc: 0.9267\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.2999 - acc: 0.9333\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.2973 - acc: 0.9333\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.2949 - acc: 0.9333\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.2924 - acc: 0.9333\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.2899 - acc: 0.9333\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.2875 - acc: 0.9333\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.2852 - acc: 0.9333\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.2828 - acc: 0.9333\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.2806 - acc: 0.9333\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.2783 - acc: 0.9333\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.2761 - acc: 0.9333\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.2738 - acc: 0.9333\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.2717 - acc: 0.9333\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.2696 - acc: 0.9333\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.2675 - acc: 0.9333\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.2654 - acc: 0.9333\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.2634 - acc: 0.9333\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.2613 - acc: 0.9333\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.2593 - acc: 0.9333\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.2572 - acc: 0.9333\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.2553 - acc: 0.9333\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.2532 - acc: 0.9333\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.2512 - acc: 0.9333\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.2492 - acc: 0.9333\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.2472 - acc: 0.9333\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.2453 - acc: 0.9333\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.2434 - acc: 0.9333\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.2416 - acc: 0.9333\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.2397 - acc: 0.9333\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.2378 - acc: 0.9333\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.2360 - acc: 0.9333\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.2342 - acc: 0.9333\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.2323 - acc: 0.9333\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.2307 - acc: 0.9333\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.2290 - acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a27d09160>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "For this network, we simply add an additional hidden layer of 6 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=6, activation='relu', input_dim=2))\n",
    "deep_model.add(Dense(units=6, activation='relu'))\n",
    "deep_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 6)                 18        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 74\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 0s - loss: 0.6519 - acc: 0.7000\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6339 - acc: 0.6933\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6177 - acc: 0.6533\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6017 - acc: 0.6533\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.5882 - acc: 0.6600\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.5743 - acc: 0.6667\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.5616 - acc: 0.6733\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.5498 - acc: 0.6800\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.5382 - acc: 0.6800\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.5274 - acc: 0.6600\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.5172 - acc: 0.6600\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.5079 - acc: 0.6600\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4983 - acc: 0.6600\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4898 - acc: 0.6733\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.4817 - acc: 0.6733\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4740 - acc: 0.6667\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.4671 - acc: 0.6733\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.4592 - acc: 0.6867\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.4530 - acc: 0.6867\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.4461 - acc: 0.6933\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4397 - acc: 0.6933\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4332 - acc: 0.6933\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4265 - acc: 0.6933\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4203 - acc: 0.7133\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4146 - acc: 0.7133\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.4092 - acc: 0.7200\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4036 - acc: 0.7333\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.3984 - acc: 0.7400\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.3934 - acc: 0.7400\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.3889 - acc: 0.7400\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.3846 - acc: 0.7400\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.3804 - acc: 0.7467\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.3762 - acc: 0.7467\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.3721 - acc: 0.7467\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.3681 - acc: 0.7467\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.3639 - acc: 0.7467\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.3599 - acc: 0.7467\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.3558 - acc: 0.7533\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.3519 - acc: 0.7533\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.3476 - acc: 0.7533\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.3435 - acc: 0.7533\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.3397 - acc: 0.7533\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.3360 - acc: 0.7533\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.3326 - acc: 0.7533\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.3289 - acc: 0.7533\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.3255 - acc: 0.7533\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.3219 - acc: 0.7533\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.3184 - acc: 0.7533\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.3149 - acc: 0.7533\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.3116 - acc: 0.7533\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.3085 - acc: 0.7533\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.3052 - acc: 0.7533\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.3022 - acc: 0.7533\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.2992 - acc: 0.7533\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.2962 - acc: 0.7533\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.2934 - acc: 0.7533\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.2904 - acc: 0.7533\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.2875 - acc: 0.7533\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.2844 - acc: 0.7533\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.2816 - acc: 0.7533\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.2783 - acc: 0.7533\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.2755 - acc: 0.7533\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.2724 - acc: 0.7533\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.2692 - acc: 0.7533\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.2661 - acc: 0.7533\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.2627 - acc: 0.7533\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.2590 - acc: 0.7533\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.2555 - acc: 0.7933\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.2521 - acc: 0.8067\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.2486 - acc: 0.8067\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.2455 - acc: 0.8133\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.2426 - acc: 0.8133\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.2408 - acc: 0.8133\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.2385 - acc: 0.8400\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.2357 - acc: 0.8600\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.2335 - acc: 0.8733\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.2311 - acc: 0.9200\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.2287 - acc: 0.9733\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.2265 - acc: 0.9733\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.2241 - acc: 0.9733\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.2219 - acc: 0.9733\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.2197 - acc: 0.9733\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.2177 - acc: 0.9800\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.2155 - acc: 0.9800\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.2134 - acc: 0.9800\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.2115 - acc: 0.9800\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.2094 - acc: 0.9800\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.2073 - acc: 0.9800\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.2053 - acc: 0.9800\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.2032 - acc: 0.9867\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.2011 - acc: 0.9867\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.1989 - acc: 0.9867\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.1963 - acc: 0.9867\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.1938 - acc: 0.9867\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.1914 - acc: 0.9867\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.1887 - acc: 0.9867\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.1864 - acc: 0.9867\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.1838 - acc: 0.9867\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.1813 - acc: 0.9933\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.1790 - acc: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a27b79eb8>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the models below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.28600505929367215, Accuracy: 0.9019607784701329\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network - Loss: 0.24825930829141654, Accuracy: 0.9215686356320101\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In a nutshell..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stack more layers](../Images/stack-more-layers.jpg)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
